{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPERACIONES BASICAS CON IMAGENES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRASLACION\n",
    "\n",
    "Para realizar una traslacion de imagen, primero debemos definir una matriz  de transformacion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/matrizdetraslacion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que nos importa aqui son los valores de tx y ty:\n",
    "\n",
    "-   Valores negativos para  tx desplazarán la imagen hacia la izquierda.\n",
    "-   Valores positivos para  tx desplazarán la imagen a la derecha\n",
    "-   Valores negativos para  tx desplazarán la imagen hacia arriba\n",
    "-   Valores positivos para  ty desplazarán la imagen hacia abajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image= cv2.imread('images/cat.1033.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ejemplo, supongamos que queremos trasladar nuestra imagen 30 píxeles a la izquierda y 12 píxeles hacia abajo :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.float32([[1,0,-30],[0,1,12]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que se define la matriz de transformación, podemos simplemente realizar la traslacion de la imagen utilizando la función cv2.warpAffine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "cv2.imshow(\"Traslacion\", shifted)\n",
    "cv2.imwrite(\"images/Traslacion.jpg\",shifted)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/Traslacion.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de transformacion M se define como una matriz de punto flotante; esto es importante porque OpenCV espera que esta matriz sea del tipo de punto flotante. La primera fila de la matriz es [1, 0, tx], donde tx es el número de píxeles que desplazaremos la imagen hacia la izquierda o hacia la derecha . Valores negativos de tx desplazarán la imagen hacia la izquierda y los valores positivos desplazarán la imagen hacia la derecha .\n",
    "\n",
    "Luego, definimos la segunda fila de la matriz como [0, 1, ty], donde ty es el número de píxeles que desplazaremos la imagen hacia arriba o hacia abajo . Valores negativos de ty desplazará la imagen hacia arriba y los valores positivos desplazarán la imagen hacia abajo .\n",
    "\n",
    "Usando esta notación, en la línea 18, podemos ver que tx = -30 y ty = 12, indica que estamos desplazando la imagen 30 píxeles hacia la izquierda y 12 píxeles hacia abajo .\n",
    "\n",
    "el metodo warpAffine espera como primer argumento la imagen , como segundo argumento la matriz de transformacion y como tercer argumento proporcionamos manualmente las dimensiones de la imagen (ancho y alto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la libreria imutils podemos directamente llamar al metodo translate para mover la imagen sin necesidad de definir ninguna matriz de transformacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted = imutils.translate(shifted,-100,-50) #100 a la izquierda y 50 hacia arriba\n",
    "cv2.imshow(\"Traslacion2\", shifted)\n",
    "cv2.imwrite(\"images/Traslacion2.jpg\",shifted)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/Traslacion2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROTACION DE IMAGENES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar a la traslación , y quizás como era de esperar, la rotación en un ángulo  se puede definir construyendo una matriz, M , en la forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/rotation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado un plano cartesiano (x, y) , esta matriz se puede usar para rotar un vector theta grados (en sentido antihorario) sobre el origen. En este caso, el origen es normalmente el centro de la imagen; sin embargo, en la práctica, podemos definir cualquier coordenada arbitraria (x, y) como nuestro centro de rotación.\n",
    "\n",
    "A partir de la imagen original, I , la imagen rotada, R, se obtiene mediante una simple multiplicación de matrices: R = I X M\n",
    "\n",
    "Sin embargo, OpenCV también proporciona la capacidad de  escalar una imagen (es decir, cambiar el tamaño)  y proporcionar un centro de rotación arbitrario alrededor del cual realizar la rotación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/rotation2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "(h,w) = (image.shape[1],image.shape[0]) #obtengo alto y ancho\n",
    "(cx,cy) = (w // 2 , h // 2) #calculo el centro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rotar la imagen 45 grados sentido antihorario alrededor del centro\n",
    "M = cv2.getRotationMatrix2D((cx,cy), 45,1.0) #obtengo la matriz de rotacion. el 1.0 es la escala. En este caso mantenemos la escala\n",
    "rotated = cv2.warpAffine(image,M,(w,h)) #aplico la transformacion a la imagen\n",
    "cv2.imwrite('images/gatorotado.jpg',rotated) #guardo la imagen\n",
    "cv2.imshow('imagen rotada',rotated) #muestro la imagen en terminal\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/gatorotado.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos OpenCV no asigna automáticamente espacio para que toda nuestra imagen llene el cuadro. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente podemos usar la libreria imutils y su metodo rotate que es mas simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = imutils.rotate(image,45,(cx,cy),1.0)\n",
    "cv2.imwrite('images/gatorotado.jpg',rotated) #guardo la imagen\n",
    "cv2.imshow('imagen rotada',rotated) #muestro la imagen en terminal\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/gatorotado.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos tenemos el mismo resultado en una sola linea de codigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = imutils.rotate_bound(image, 45)\n",
    "cv2.imwrite('images/gatorotado2.jpg',rotated) #guardo la imagen\n",
    "cv2.imshow('imagen rotada',rotated) #muestro la imagen en terminal\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/gatorotado2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función expandirá automáticamente la matriz de imágenes de modo que toda la imagen rotada quepa dentro de ella."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REDIMENSIONANDO IMAGENES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalar, o simplemente cambiar el tamaño , es el proceso de aumentar o disminuir el tamaño de una imagen en términos de ancho y alto.\n",
    "\n",
    "Al cambiar el tamaño de una imagen, es importante tener en cuenta la relación de aspecto (Aspect Ratio) , que es la relación entre el ancho y la altura de una imagen. Ignorar la relación de aspecto puede dar lugar a imágenes redimensionadas que parezcan comprimidas y distorsionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 304, 3)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('images/dog.1033.jpg')\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/dog.1033.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect ratio: 0.4934210526315789 \n",
      " Dimension final: (150, 185)\n"
     ]
    }
   ],
   "source": [
    "#vemos que tiene 375 de alto y 304 pixeles de ancho.\n",
    "#Redimensionemos para que tenga 150 de ancho , pero sin perder la relacion de aspecto.\n",
    "\n",
    "r = 150.0/image.shape[1]\n",
    "dim = (150, int(image.shape[0]*r))\n",
    "print('aspect ratio: {} \\n Dimension final: {}'.format(r,dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizeImage = cv2.resize(image,dim,interpolation=cv2.INTER_AREA)\n",
    "cv2.imwrite('images/resizeImage.jpg',resizeImage)\n",
    "cv2.imshow('Resize Image',resizeImage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/resizeImage.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al cambiar el tamaño de una imagen, debemos tener en cuenta la relación de aspecto de la imagen. La relación de aspecto es la relación proporcional del ancho y el alto de la imagen:\n",
    "\n",
    "relación_de_ aspecto = ancho_de_imagen / altura_de_imagen\n",
    "\n",
    "Si no somos conscientes de la relación de aspecto, nuestro cambio de tamaño arrojará resultados que parecen distorsionados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos lo mismo utilizando la libreria imutils junto a su metodo resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el codigo anterior hemos utilizado método de interpolación  cv2.INTER_AREA. El objetivo de una función de interpolación es examinar vecindarios de píxeles y usar estos vecindarios para aumentar o disminuir ópticamente el tamaño de la imagen sin introducir distorsiones (o al menos la menor cantidad de distorsiones posible).\n",
    "\n",
    "El primer método es la interpolación del vecino más cercano, especificada por cv2.INTER_NEAREST. Este método es el enfoque más simple para la interpolación. En lugar de calcular promedios ponderados de píxeles vecinos o aplicar reglas complicadas, este método simplemente encuentra el píxel vecino \"más cercano\" y asume el valor de intensidad. Si bien este método es rápido y simple, la calidad de la imagen redimensionada tiende a ser relativamente pobre y puede generar artefactos en forma de \"bloques\".\n",
    "\n",
    "En segundo lugar, tenemos el método cv2.INTER_LINEAR , que realiza una interpolación bilineal: este es el método que OpenCV utiliza de forma predeterminada al cambiar el tamaño de las imágenes.\n",
    "En tercer lugar, tenemos el método de interpolación cv2.INTER_AREA. Finalmente, tenemos cv2.INTER_CUBIC y cv2.INTER_LANCZOS4.\n",
    "Estos métodos son más lentos (ya que ya no usan interpolación lineal simple y en su lugar usan splines) y utilizan interpolación bicúbica sobre vecindarios de píxeles cuadrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizeimage2 = imutils.resize(image,width=150) #el metdo se encarga de mantener la relacion de aspecto\n",
    "cv2.imwrite('images/resizeimage2.jpg',resizeimage2)\n",
    "cv2.imshow('Resize Image',resizeimage2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/resizeimage2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLIP IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar a la rotación de imágenes , OpenCV también proporciona métodos para voltear una imagen a través de su eje x o y . Aunque las operaciones de volteo se usan con menos frecuencia, aún son muy valiosas de aprender, y por razones que quizás no consideres más importantes.\n",
    "\n",
    "Por ejemplo, imaginemos trabajar para una pequeña empresa de nueva creación que quiere construir un clasificador de aprendizaje automático para detectar rostros dentro de las imágenes. Necesitaríamos un conjunto de datos de caras de ejemplo que nuestro algoritmo podría usar para \"aprender\" qué es una cara. Pero desafortunadamente, la compañía solo nos ha proporcionado un pequeño conjunto de datos de 20 caras y no tenemos los medios para adquirir más datos.\n",
    "\n",
    "¿Asi que que hacemos?\n",
    "\n",
    "¡Aplicamos operaciones de volteo para aumentar nuestro conjunto de datos!\n",
    "\n",
    "Podemos voltear horizontalmente cada imagen de la cara (ya que una cara sigue siendo una cara, ya sea reflejada o no) y usar estas versiones reflejadas como datos de entrenamiento adicionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos voltear una imagen alrededor del eje x , eje y , o incluso ambos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = cv2.flip(image,1) #el valor de uno indica flip horizontal\n",
    "flipped2= cv2.flip(image,0) #el valor de cero indica flip vertical\n",
    "cv2.imwrite('images/verticalflipped.jpg',flipped2)\n",
    "cv2.imshow('Resize Image',flipped2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/horizontalflipped.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/verticalflipped.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECORTAR IMAGEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recortas es la accion  de seleccionar y extraer la Región de interés (o simplemente, ROI)  de la imagen que nos interesa.\n",
    "Por ejemplo, en una aplicación de detección de rostros, es posible que queramos recortar el rostro de una imagen. Imagen fuente PYIMAGESEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/SLICING.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando recortamos una imagen, queremos eliminar las partes externas de la imagen que no nos interesan. Normalmente nos referimos a este proceso como seleccionar nuestra Región de interés , o más simplemente, nuestro ROI.\n",
    "\n",
    "Podemos lograr el recorte de imágenes usando el corte de matriz NumPy.\n",
    "\n",
    "Comencemos por inicializar una lista NumPy con valores que van desde [0, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "I = np.arange(0,25)\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora redimensionemos esta lista a una matriz 2D\n",
    "I=I.reshape((5,5))\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1],\n",
       "       [ 5,  6],\n",
       "       [10, 11]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Supongamos que queremos extraer los pixeles desde x=0 y=0 a x=2 y=3\n",
    "I[0:3, 0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como observamos hemos extraidos 3 filas y 2 columnas.\n",
    "\n",
    "Al aplicar el corte de matriz NumPy a las imágenes, extraemos el ROI usando la siguiente sintaxis:\n",
    "- roi = imagen [ startY: endY, startX: endX ]\n",
    "\n",
    "El [startY: endY] proporciona nuestras filas (ya que el eje y es nuestro número de filas) mientras que [startX: endX] proporciona nuestras columnas (ya que el eje x es el número de columnas) en la imagen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(347, 627, 3)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('images/tiomaridopampita.png')\n",
    "cv2.imshow('Image',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print(image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/tiomaridopampita.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "rostro = image[20:200,130:280] ##extraigo el rostro. \n",
    "cv2.imwrite('images/andino.jpg',rostro)\n",
    "cv2.imshow('Andino',rostro)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/andino.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El rostro lo extraje por prueba y error ya que no aun no vimos los algoritmos de deteccion de rostros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPERACION ARITMETICAS EN IMAGENES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las imagenes al tratarse como matrices podemos realizar las operacion de suma, resta como cualquier matriz. \n",
    "Pero debemos tener el cuenta los intervalos que aceptan las imagenes [0,255]\n",
    "Sin embargo, asegúrese de tener en cuenta que existe una diferencia entre la adición de OpenCV y NumPy. NumPy realizará aritmética de módulo y \"envolver\". Por otro lado, OpenCV realizará el recorte y garantizará que los valores de los píxeles nunca caigan fuera del rango [0, 255] ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/aritmeticaimagenes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que entendemos los conceptos básicos de la aritmética de imágenes, es posible que se pregunte dónde usaríamos la aritmética de imágenes en el mundo real.\n",
    "\n",
    "Los ejemplos básicos incluyen:\n",
    "\n",
    "- Ajustar el brillo y el contraste agregando o restando una cantidad determinada (por ejemplo, agregando 50 a todos los valores de píxeles para aumentar el brillo de una imagen)\n",
    "- Trabajando con mezcla alfa y transparencia, como lo hacemos en este tutorial.\n",
    "- Creación de filtros similares a los de Instagram : estos filtros son simplemente funciones matemáticas aplicadas a las intensidades de píxeles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las imágenes son matrices NumPy almacenadas como enteros de 8 bits sin signo (unit8)\n",
    "con valores en el rango [0, 255]; al usar las funciones suma / resta en OpenCV, estos valores se  recortarán *a este rango,\n",
    "incluso si quedan fuera del rango [0, 255] después de aplicar la operación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max de 255: [[255]]\n",
      "min de 0: [[0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "suma = cv2.add(np.uint8([200]), np.uint8([100])) #por mas que la suma da 300 el metodo add sabe que el maximo es 255\n",
    "resta = cv2.subtract(np.uint8([50]), np.uint8([100])) #por mas que la resta de -50 el metodo substract sabe que el minimo es 0\n",
    "print(\"max de 255: {}\".format(suma))\n",
    "print(\"min de 0: {}\".format(resta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante tener en cuenta la salida deseada al realizar aritmética de números enteros:\n",
    "\n",
    "- ¿Quiere que se recorten todos los valores si quedan fuera del rango [0, 255] ? Luego use los métodos integrados de OpenCV para la aritmética de imágenes.\n",
    "- ¿Quiere operaciones aritméticas de módulo y tener valores ajustados si caen fuera del rango de [0, 255] ? Luego, simplemente agregue y reste las matrices NumPy como lo haría normalmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/tiomaridopampita.png')\n",
    "M = np.ones(image.shape,dtype='uint8')*100\n",
    "suma =cv2.add(image,M)\n",
    "resta =cv2.subtract(image,M)\n",
    "cv2.imwrite('images/tioconmenosbrillo.jpg',resta)\n",
    "cv2.imwrite('images/tioconbrillo.jpg',suma)\n",
    "cv2.imshow('Tio de marido de pampita con brillo',suma)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/tioconbrillo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/tioconmenosbrillo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPERACIONES PIXEL A PIXEL (AND, OR ,NOT ,XOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien son muy básicas y de bajo nivel, estas cuatro operaciones son fundamentales para el procesamiento de imágenes, especialmente cuando se trabaja con máscaras/filtros como veremos mas adelante.\n",
    "\n",
    "Las operaciones bit a bit funcionan de manera binaria y se representan como imágenes en escala de grises. Un píxel determinado se \"apaga\" si tiene un valor de cero, y se \"enciende\" si el píxel tiene un valor mayor que cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dibujamos un rectangulo en imagen en negro\n",
    "rectangle = np.zeros((300, 300), dtype=\"uint8\")#imagen en negro de 300 x 300\n",
    "cv2.rectangle(rectangle, (25, 25), (275, 275), 255, -1) #con -1 el rectangulo se rellena\n",
    "cv2.imwrite(\"images/rectangulo.jpg\", rectangle)\n",
    "cv2.imshow(\"Rectangulo\", rectangle)\n",
    "\n",
    "circle = np.zeros((300, 300), dtype = \"uint8\")\n",
    "cv2.circle(circle, (150, 150), 150, 255, -1)\n",
    "cv2.imwrite(\"images/circulo.jpg\", circle)\n",
    "cv2.imshow(\"Circulo\", circle)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/rectangulo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/circulo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si consideramos estas imágenes de entrada, veremos que solo tienen dos valores de intensidad de píxeles, o bien el píxel es 0(negro) o el píxel es mayor que cero (blanco). Llamamos imágenes binarias a las imágenes que solo tienen dos valores de intensidad de píxeles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un 'AND' bit a bit es solo 'Verdadero' cuando ambas entradas tienen un valor que es 'ON' - en este caso, la función cv2.bitwise_and examina\n",
    "cada píxel del rectángulo y el círculo; si  AMBOS  píxeles tienen un valor mayor que cero, entonces el píxel se enciende (es decir es 255)\n",
    "en la imagen de salida; de lo contrario, el valor de salida se establece en 'APAGADO' (es decir, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwiseAnd = cv2.bitwise_and(rectangle, circle)\n",
    "cv2.imshow(\"AND\", bitwiseAnd)\n",
    "cv2.imwrite(\"images/operacionAND.jpg\", bitwiseAnd)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/operacionAND.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "notop = cv2.bitwise_not(circle)\n",
    "cv2.imshow(\"AND\", notop)\n",
    "cv2.imwrite(\"images/operacionNot.jpg\", notop)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/operacionNot.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "orOp = cv2.bitwise_or(rectangle,circle)\n",
    "cv2.imshow(\"OR\", orOp)\n",
    "cv2.imwrite(\"images/operacionOR2.jpg\", orOp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/operacionOR2.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "xorOp = cv2.bitwise_xor(rectangle,circle)\n",
    "cv2.imshow(\"XOR\", xorOp)\n",
    "cv2.imwrite(\"images/operacionXOR1.jpg\", xorOp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/operacionXOR1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMAGE MASKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una máscara nos permite enfocarnos solo en las partes de la imagen que nos interesan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, digamos que estamos construyendo un sistema de visión por computadora para reconocer rostros. La única parte de la imagen que nos interesa encontrar y describir son las partes de la imagen que contienen caras; simplemente no nos importa el resto del contenido de la imagen. Siempre que podamos encontrar las caras en la imagen, podemos construir una máscara para mostrar solo las caras en la imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra aplicación de enmascaramiento de imágenes que encontrará es la combinación alfa y la transparencia. Al aplicar transparencia a imágenes con OpenCV, debemos decirle a OpenCV a qué partes de la transparencia de la imagen se deben aplicar y a qué no; las máscaras nos permiten hacer esa distinción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image = cv2.imread('images/tiomaridopampita.png')\n",
    "cv2.imshow(\"imagen\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/tiomaridopampita.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una máscara tiene el mismo tamaño que nuestra imagen, pero solo tiene dos valores de píxeles\n",
    ", 0 y 255: los píxeles con un valor de 0 (fondo) son ignorado en la imagen original mientras que enmascara píxeles con un valor de\n",
    "255 (primer plano) se pueden mantener.\n",
    "\n",
    "\n",
    "Aplique nuestra máscara - observe cómo solo la persona en la imagen es recortada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros (image.shape[:2],dtype='uint8')\n",
    "cv2.rectangle(mask,(140,40),(270,180),255,-1)\n",
    "cv2.imshow(\"mask\", mask)\n",
    "cv2.imwrite(\"images/mask1.jpg\", mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/mask1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked = cv2.bitwise_and(image,image,mask=mask)\n",
    "cv2.imwrite(\"images/masked1.jpg\", masked)\n",
    "cv2.imshow('Mascara aplicada',masked)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<caption>](images/masked1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIVIDIENDO Y JUNTANDO CANALES CON OPENCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como sabemos, una imagen a color está representada por tres componentes: un canal rojo, verde y azul.\n",
    "\n",
    "Y aunque hemos analizado brevemente las representaciones en escala de grises y binarias de una imagen, es posible que se esté preguntando:\n",
    "\n",
    "¿Cómo accedo a cada canal rojo, verde y azul individual de una imagen?\n",
    "\n",
    "Dado que las imágenes en OpenCV se representan internamente como matrices NumPy, el acceso a cada canal se puede lograr de múltiples maneras. Sin embargo, nos centraremos en los dos métodos principales que debe utilizar: cv2.split y cv2.merge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo general, pensamos en imágenes en el espacio de color RGB: el píxel rojo primero, el píxel verde en segundo lugar y el píxel azul en tercer lugar. Sin embargo, OpenCV almacena imágenes RGB como matrices NumPy en orden de canal inverso. En lugar de almacenar una imagen en orden RGB, almacena la imagen en orden BGR. Así desempaquetamos la tupla en orden inverso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/tiomaridopampita.png')\n",
    "(b,g,r) = cv2.split(image)\n",
    "cv2.imwrite(\"images/canalrojo.jpg\", r)\n",
    "cv2.imwrite(\"images/canalverde.jpg\", g)\n",
    "cv2.imwrite(\"images/canalazul.jpg\", b)\n",
    "# mostrar cada canal individualmente\n",
    "\n",
    "cv2.imshow (\"Rojo\", r) #SUPERIOR DERECHA. VEMOS COMO EL TITULO ES NARANJA Y EN EL CANAL ROJO SE VE BASTANTE BLANCO YA QUE EL ROJO APORTA MUCHO\n",
    "cv2.imshow (\"Verde\", g) #INFERIOR IZQUIERDA\n",
    "cv2.imshow (\"Azul\", b) #INFERIOR DERECHA. vVEMOS EL SACO DE ANDINO QUE EN EL CANAL AZUL SE VE BLANCO YA QUE APORTA EL AZUL.\n",
    "cv2.waitKey (0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<ORIGINAL>](images/tiomaridopampita.png)\n",
    "![<ROJO>](images/canalrojo.jpg)\n",
    "![<VERDE>](images/canalverde.jpg)\n",
    "![<AZUL>](images/canalazul.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUSIONAR LA IMAGEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n"
     ]
    }
   ],
   "source": [
    "merged = cv2.merge([b,g,r])\n",
    "cv2.imwrite(\"images/merged.jpg\", merged)\n",
    "\n",
    "cv2.imshow (\"Merged\", merged) \n",
    "cv2.waitKey (0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![<ORIGINAL>](images/merged.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado tambien podemos visualizar cada canal en \"color\" en lugar de \"escala de grises\". Esta es estrictamente una técnica de visualización y no algo que usaríamos en una aplicación estándar de procesamiento de imágenes o visión por computadora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiza cada canal en color\n",
    "ceros = np.zeros (image.shape [:2], dtype = \"uint8\")\n",
    "cv2.imwrite(\"images/canalrojook1.jpg\", cv2.merge ([ceros, ceros, r]))\n",
    "cv2.imwrite(\"images/canalverdeok1.jpg\", cv2.merge ([ceros, g, ceros]))\n",
    "cv2.imwrite(\"images/canalazulok1.jpg\",  cv2.merge ([b, ceros, ceros]))\n",
    "cv2.imshow (\"Rojo\", cv2.merge ([ceros, ceros, r]))\n",
    "cv2.imshow (\"Verde\", cv2.merge ([ceros, g, ceros]))\n",
    "cv2.imshow (\"Azul\", cv2.merge ([b, ceros, ceros]))\n",
    "cv2.waitKey (0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![<ORIGINAL>](images/tiomaridopampita.png)\n",
    "![<ROJOo>](images/canalrojook1.jpg)\n",
    "![<VERDE>](images/canalverdeok1.jpg)\n",
    "![<AZUL>](images/canalazulok1.jpg)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5b1ca146a2b6c1dad98eb34c68ce0978784e2a044fb88d9a2019968fdd7143a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ambienteML': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
